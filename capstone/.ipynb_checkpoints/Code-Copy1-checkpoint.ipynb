{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# %load PCA.py\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "import nltk\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Variant   (3321, 4)\n",
      "Train Text      (3321, 2)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(\"training_variants\")\n",
    "train_text = pd.read_csv(\"training_text\", sep=\"\\|\\|\", engine=\"python\", skiprows=1, names=[\"ID\", \"Text\"])\n",
    "print(\"Train Variant\".ljust(15), train.shape)\n",
    "print(\"Train Text\".ljust(15), train_text.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA for Gene and Variation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Gene</th>\n",
       "      <th>Variation</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>FAM58A</td>\n",
       "      <td>Truncating Mutations</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>CBL</td>\n",
       "      <td>W802*</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>CBL</td>\n",
       "      <td>Q249E</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>CBL</td>\n",
       "      <td>N454D</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>CBL</td>\n",
       "      <td>L399V</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID    Gene             Variation  Class\n",
       "0   0  FAM58A  Truncating Mutations      1\n",
       "1   1     CBL                 W802*      2\n",
       "2   2     CBL                 Q249E      2\n",
       "3   3     CBL                 N454D      3\n",
       "4   4     CBL                 L399V      4"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID           0\n",
       "Gene         0\n",
       "Variation    0\n",
       "Class        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isnull().sum() # check if there is missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID      0\n",
       "Text    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_text.isnull().sum() # check if there is missing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we dont have any mising data in dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of unique train Genes 264\n",
      "Count of unique train Variation 2996\n"
     ]
    }
   ],
   "source": [
    "# Unique ones\n",
    "print('Count of unique train Genes',len(train.Gene.unique()))\n",
    "print('Count of unique train Variation',len(train.Variation.unique()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Variation there are 2996 unique values in total of 3321 data. So it is hard to think direct correlation between them\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Gene\n",
       "BRCA1    264\n",
       "TP53     163\n",
       "EGFR     141\n",
       "PTEN     126\n",
       "BRCA2    125\n",
       "Name: ID, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.groupby('Gene').ID.count().sort_values(ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variation\n",
       "Truncating Mutations    93\n",
       "Deletion                74\n",
       "Amplification           71\n",
       "Fusions                 34\n",
       "Overexpression           6\n",
       "Name: ID, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.groupby('Variation').ID.count().sort_values(ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x11f5689b0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZEAAAEICAYAAACeSMncAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11f571f98>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "df=(train.Gene.value_counts(normalize=True)*100)\n",
    "df[df>1].plot(kind='barh',title='% of GENES in training set')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x11d8f8400>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEFCAYAAADkP4z+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAFs9JREFUeJzt3X2wHXd93/H3xzIm+DnFF4MtC5lB1IgGMyBsUsyDB3Bs\nbBChA7FNIaVxFLd4DAOk1ZAMTScJNQkNDY2JRgXDMOCYh+JE1AIDA4YQ4yAZHBuBRYUQWPLzM8YE\nS/jbP3ZFjm+vfPdKR/co+r1fM3fu2d3fb/e751x9ds9vz1mlqpAkteOASRcgSZpfBr8kNcbgl6TG\nGPyS1BiDX5IaY/BLUmMM/kYl+YMkH53g9q9Kcl7/+HVJPj/GdW9I8uL+8Vj3M8k7knxgXOsbWe9Y\nn4Pd2P4Lkmyc1PY1vwz+/ViSc5OsT/JAkluSfDbJKZOua7qq+lhVnTZbuyQfTvJHA9b3jKq6ak/r\nSvLiJFunrftdVXXenq57uqHPwUzGcXCrqr+tqn+5J+uYq6Gvp8bP4N9PJXkr8D+AdwFHA4uAi4FX\nTrKuvSnJgZOuYV+Ujv/W9U+qyp/97Ac4AngAeM2jtPkD4KMj058EbgXuA74KPGNk2cuB7wA/BrYB\nb+/nHwX8H+Be4G7gb4EDdrG9lwE39uv/C+ArwHn9sn8HfK1/HOC9wO3A/cANwL8CVgDbgYf6fftM\n334L8J+B64GfAQf28146sp+fAj7e1/9N4MSRugp46sj0h4E/Ag4Bfgo83G/vAeCYGZ63VwIb+ufg\nKuDpI8u2AG/va7uvr+GXdvH8/OI5GKnrfOD/9uu+GMgM/U7vn5PtfY3/0M+/Cvhj4O/6/Xgq8Ebg\nu/3zsBn4nZH1vBjYupu1P7V/Pe8D7gQ+PrLsBOAL/d/HRuC1/fwZX09/5ufHs4D9068CvwRcPoc+\nnwWWAE+gC8ePjSz7IF1IHEYXwl/q578N2ApM0b2reAddYD1CkqOATwO/T3ew+D7w/F3UcRrwQuBp\ndAew1wJ3VdXqvqY/qapDq+oVI33OAc4EjqyqHTOsczndge1fAJcCf53kMbt8JoCq+glwBnBzv71D\nq+rmafv1NOCvgLf0z8Fa4DNJDhpp9lq6cD4eeCZdwA91FvDcvt9rgV+boc7P0b2r+3hf44kji19P\nF7CHAT+kO5ieBRxOdxB4b5JnP8r2h9b+h8DngV8GFgL/EyDJIXShfynd39XZwPuTLJ3l9dReZvDv\nnx4P3LmLEJxRVV1SVT+uqp/RndWemOSIfvF2YGmSw6vqnqr65sj8JwFPrqrt1Y0Tz3Tzp5cDG6rq\nU1W1nW4I6tZdlLKdLqhOoDvD/W5V3TJL+e+rqpuq6qe7WH7tyLb/jO6g+LxZ1jnEbwBXVNUX+nW/\nB3gc8K+n1XZzVd0NfAZ41hzWf1FV3VtVPwK+PMe+AB+uqg1VtaN/fa6oqu9X5yt0Yf2CR+k/tPbt\nwJOBY6rqH6vqa/38s4AtVfWhvoZvAf8beM0c90NjZvDvn+4Cjho65p1kQZKLknw/yf10b/OhOzsH\n+Dd04f3DJF9J8qv9/D8FNgGfT7I5ycpdbOIY4KadE/3B4aaZGlbVl+iGgi4Gbk+yOsnhs+zCjOua\naXlVPUz3LuWYWfoMcQzdmfToum8Cjh1pM3qAexA4dA7r35O+MO15SXJGkmuS3J3kXrrX9KiZu85p\n+/+JbojuG/0nqv59P//JwMlJ7t35A7wOeOIc90NjZvDvn75ON979qoHtz6UbDnkp3fDK4n5+AKpq\nXVUtp3u7/tfAJ/r5P66qt1XVU+jGut+a5CUzrP8W4LidE0kyOj1dVb2vqp4DLKUb8vndnYt21WWW\n/Rvd9gF0wxE7h20eBA4eaTsaSrOt92a6cNu57p37tW2WfuM26/OS5LF0Z9vvAY6uqiPphqayxxuv\nurWqfruqjgF+h24456l0B56vVNWRIz+HVtV/mKVu7WUG/36oqu4D3glcnORVSQ5O8pj+jO9PZuhy\nGN2B4i66EHzXzgVJDuo/Y35EP5xxP90FT5KcleSpfeDdB/x857JprgCekeTV/buQC9nFWV+S5yY5\nuR+D/wnwjyPrvA14yhyfDoDnjGz7Lf2+XtMvuw44t3/XczrwopF+twGPHxnymu4TwJlJXtLX+7Z+\n3VfvRo174jZg8Syf3DkIeCxwB7AjyRl011P2WJLXJFnYT95DF+gP0134f1qS1/d/f4/pX9+nj9S9\nO6+n9pDBv5+qqv8OvJXuguoddGdfF9CdsU/3Ebohi210n965Ztry1wNb+mGg8+nerkN3MfiLdJ/K\n+Drw/qr68gy13Ek3rnsR3cFlCd2nTWZyOPC/6ALkh337P+2XfZDuWsO9SWbaj135G7rx+Hv6fXl1\nfxADeDPwCrpPzryOkeenqm6ku3i7ud/mI4aHqmoj8G/pLmbe2a/nFVX10BxqG4dP9r/vSvLNmRpU\n1Y/pDrifoHsezgXWjGn7zwX+PskD/TrfXFWb+22eRndR92a6oaN30x2AYPdfT+2hzHwtTpK0v/KM\nX5IaY/BLUmMGBX+S05NsTLJppo/sJVme5Pok1/X3hjllaF9J0vyadYw/yQLge3Rfud8KrAPOqarv\njLQ5FPhJVVWSZwKfqKoThvSVJM2vIWf8JwGb+qv0DwGX0X3m+xeq6oGRb2wewj99PnfWvpKk+TXk\nm53H8shvAG4FTp7eKMmvA/+N7ks+Z86l73RHHXVULV68eEBpkiSAa6+99s6qmhrSdmy3sa2qy4HL\nk7yQ7qZNL51L/yQr6G4oxaJFi1i/fv24SpOk/V6SH87eqjNkqGcbj/x6/UIe5SvpVfVV4Cn9HRkH\n962q1VW1rKqWTU0NOmhJknbDkOBfByxJcnx/u9mzmfaNv5Gv7dPf5vWxdN+4nLWvJGl+zTrUU1U7\nklwAXAksAC6pqg1Jzu+Xr6K7e+Mbkmyn+08ffqO/2Dtj3720L5KkAfbJWzYsW7asHOOXpOGSXFtV\ny4a09Zu7ktQYg1+SGmPwS1JjDH5JaszYvsA13xavvGIs69ly0ZmzN5Kk/Yhn/JLUGINfkhpj8EtS\nYwx+SWqMwS9JjTH4JakxBr8kNcbgl6TGGPyS1BiDX5IaY/BLUmMMfklqjMEvSY0x+CWpMQa/JDXG\n4Jekxhj8ktQYg1+SGmPwS1JjDH5JaozBL0mNMfglqTGDgj/J6Uk2JtmUZOUMy1+X5PokNyS5OsmJ\nI8u29POvS7J+nMVLkubuwNkaJFkAXAy8DNgKrEuypqq+M9LsB8CLquqeJGcAq4GTR5afWlV3jrFu\nSdJuGnLGfxKwqao2V9VDwGXA8tEGVXV1Vd3TT14DLBxvmZKkcRkS/McCN41Mb+3n7cpvAZ8dmS7g\ni0muTbJi7iVKksZp1qGeuUhyKl3wnzIy+5Sq2pbkCcAXktxYVV+doe8KYAXAokWLxlmWJGnEkDP+\nbcBxI9ML+3mPkOSZwAeA5VV11875VbWt/307cDnd0NH/p6pWV9Wyqlo2NTU1fA8kSXMyJPjXAUuS\nHJ/kIOBsYM1ogySLgE8Dr6+q743MPyTJYTsfA6cB3x5X8ZKkuZt1qKeqdiS5ALgSWABcUlUbkpzf\nL18FvBN4PPD+JAA7qmoZcDRweT/vQODSqvrcXtkTSdIgg8b4q2otsHbavFUjj88Dzpuh32bgxOnz\nJUmT4zd3JakxBr8kNcbgl6TGGPyS1BiDX5IaY/BLUmMMfklqjMEvSY0x+CWpMQa/JDXG4Jekxhj8\nktQYg1+SGmPwS1JjDH5JaozBL0mNMfglqTEGvyQ1xuCXpMYY/JLUGINfkhpj8EtSYwx+SWqMwS9J\njTH4JakxBr8kNebASRewP1m88oqxrWvLRWeObV2SNGrQGX+S05NsTLIpycoZlr8uyfVJbkhydZIT\nh/aVJM2vWYM/yQLgYuAMYClwTpKl05r9AHhRVf0K8IfA6jn0lSTNoyFn/CcBm6pqc1U9BFwGLB9t\nUFVXV9U9/eQ1wMKhfSVJ82tI8B8L3DQyvbWftyu/BXx2N/tKkvaysV7cTXIqXfCfsht9VwArABYt\nWjTOsiRJI4ac8W8DjhuZXtjPe4QkzwQ+ACyvqrvm0hegqlZX1bKqWjY1NTWkdknSbhgS/OuAJUmO\nT3IQcDawZrRBkkXAp4HXV9X35tJXkjS/Zh3qqaodSS4ArgQWAJdU1YYk5/fLVwHvBB4PvD8JwI7+\n7H3GvntpXyRJAwwa46+qtcDaafNWjTw+DzhvaF9J0uR4ywZJaozBL0mNMfglqTEGvyQ1xuCXpMYY\n/JLUGINfkhpj8EtSYwx+SWqMwS9JjTH4JakxBr8kNcbgl6TGGPyS1BiDX5IaY/BLUmPG+p+ta9+z\neOUVY1vXlovOHNu6JE2OZ/yS1BiDX5IaY/BLUmMMfklqjMEvSY0x+CWpMQa/JDXG4Jekxhj8ktQY\ng1+SGjMo+JOcnmRjkk1JVs6w/IQkX0/ysyRvn7ZsS5IbklyXZP24Cpck7Z5Z79WTZAFwMfAyYCuw\nLsmaqvrOSLO7gQuBV+1iNadW1Z17Wqwkac8NOeM/CdhUVZur6iHgMmD5aIOqur2q1gHb90KNkqQx\nGhL8xwI3jUxv7ecNVcAXk1ybZMVcipMkjd983Jb5lKraluQJwBeS3FhVX53eqD8orABYtGjRPJQl\nSW0acsa/DThuZHphP2+QqtrW/74duJxu6GimdqurallVLZuamhq6eknSHA0J/nXAkiTHJzkIOBtY\nM2TlSQ5JctjOx8BpwLd3t1hJ0p6bdainqnYkuQC4ElgAXFJVG5Kc3y9fleSJwHrgcODhJG8BlgJH\nAZcn2bmtS6vqc3tnVyRJQwwa46+qtcDaafNWjTy+lW4IaLr7gRP3pEBJ0nj5zV1JaozBL0mNMfgl\nqTEGvyQ1xuCXpMbMxzd3pUdYvPKKsa1ry0Vnjm1dUis845ekxhj8ktQYg1+SGmPwS1JjDH5JaozB\nL0mNMfglqTEGvyQ1xuCXpMYY/JLUGINfkhpj8EtSYwx+SWqMwS9JjTH4JakxBr8kNcbgl6TGGPyS\n1BiDX5IaY/BLUmMMfklqzKDgT3J6ko1JNiVZOcPyE5J8PcnPkrx9Ln0lSfNr1uBPsgC4GDgDWAqc\nk2TptGZ3AxcC79mNvpKkeTTkjP8kYFNVba6qh4DLgOWjDarq9qpaB2yfa19J0vwaEvzHAjeNTG/t\n5w2xJ30lSXvBPnNxN8mKJOuTrL/jjjsmXY4k7beGBP824LiR6YX9vCEG962q1VW1rKqWTU1NDVy9\nJGmuhgT/OmBJkuOTHAScDawZuP496StJ2gsOnK1BVe1IcgFwJbAAuKSqNiQ5v1++KskTgfXA4cDD\nSd4CLK2q+2fqu7d2RpI0u1mDH6Cq1gJrp81bNfL4VrphnEF9JUmTs89c3JUkzQ+DX5IaY/BLUmMM\nfklqjMEvSY0x+CWpMQa/JDXG4Jekxgz6ApfUgsUrrxjLerZcdOZY1iPtLZ7xS1JjDH5JaozBL0mN\nMfglqTEGvyQ1xuCXpMb4cU5pH+ZHTLU3eMYvSY0x+CWpMQa/JDXG4Jekxhj8ktQYg1+SGmPwS1Jj\nDH5JaozBL0mNMfglqTEGvyQ1xuCXpMYMCv4kpyfZmGRTkpUzLE+S9/XLr0/y7JFlW5LckOS6JOvH\nWbwkae5mvTtnkgXAxcDLgK3AuiRrquo7I83OAJb0PycDf9n/3unUqrpzbFVLknbbkDP+k4BNVbW5\nqh4CLgOWT2uzHPhIda4BjkzypDHXKkkagyHBfyxw08j01n7e0DYFfDHJtUlW7GojSVYkWZ9k/R13\n3DGgLEnS7piPi7unVNWz6IaD3pTkhTM1qqrVVbWsqpZNTU3NQ1mS1KYhwb8NOG5kemE/b1Cbqtr5\n+3bgcrqhI0nShAwJ/nXAkiTHJzkIOBtYM63NGuAN/ad7ngfcV1W3JDkkyWEASQ4BTgO+Pcb6JUlz\nNOuneqpqR5ILgCuBBcAlVbUhyfn98lXAWuDlwCbgQeCNffejgcuT7NzWpVX1ubHvhSRpsEH/2XpV\nraUL99F5q0YeF/CmGfptBk7cwxolSWPkN3clqTEGvyQ1xuCXpMYY/JLUGINfkhpj8EtSYwx+SWqM\nwS9JjTH4JakxBr8kNcbgl6TGDLpXjyTttHjlFWNb15aLzhzbujScZ/yS1BiDX5IaY/BLUmMMfklq\njMEvSY0x+CWpMQa/JDXG4Jekxhj8ktQYg1+SGuMtGyT9s+dtJObGM35JaozBL0mNMfglqTGO8UvS\nXrAvX3cYdMaf5PQkG5NsSrJyhuVJ8r5++fVJnj20ryRpfs0a/EkWABcDZwBLgXOSLJ3W7AxgSf+z\nAvjLOfSVJM2jIWf8JwGbqmpzVT0EXAYsn9ZmOfCR6lwDHJnkSQP7SpLm0ZAx/mOBm0amtwInD2hz\n7MC+ACRZQfduAeCBJBsH1Dabo4A7H61B3j2GrczNrDXBvlmXNQHWNJR/58ONq6YnD93gPnNxt6pW\nA6vHuc4k66tq2TjXuaf2xZpg36zLmoaxpuH2xbomUdOQ4N8GHDcyvbCfN6TNYwb0lSTNoyFj/OuA\nJUmOT3IQcDawZlqbNcAb+k/3PA+4r6puGdhXkjSPZj3jr6odSS4ArgQWAJdU1YYk5/fLVwFrgZcD\nm4AHgTc+Wt+9siczG+vQ0ZjsizXBvlmXNQ1jTcPti3XNe02pqvnepiRpgrxlgyQ1xuCXpMYY/JLU\nmP0m+JNcmOS42VtOVpKPTLqGfVWSE5K8JMmh0+afPqF6Tk5yeP/4cUn+a5LPJHl3kiMmUdN0SU5J\n8tYkp024jpOSPLd/vLSv6eUTrukpSd6e5M+T/FmS83e+nhOq56Akb0jy0n763CR/keRNSR4zr7Xs\nLxd3k9wH/AT4PvBXwCer6o4J1zT9o6sBTgW+BFBVr5z3omaR5I1V9aEJbPdC4E3Ad4FnAW+uqr/p\nl32zqp79aP33Uk0bgBP7T6etpvvE2qeAl/TzXz2Bmr5RVSf1j3+b7jm7HDgN+ExVXTSBmv4L3f24\nDgS+QPft/C8DLwOurKo/nkBNFwJnAV+l+8Tht4B7gV8H/mNVXTWBmj5G9xwd3NdyKPBpur+nVNVv\nzlsxVbVf/NC9sAfQ/QP4IHAH8DngN4HDJlTTN4GPAi8GXtT/vqV//KJJP2e7qPlHE9ruDcCh/ePF\nwHq68Af41oRq+u7oazlt2XUTqulbI4/XAVP940OAGyb42i2gC7T7gcP7+Y8Drp9kTf3jg4Gr+seL\nJvj3dH3/+0DgtpH6Mt/P0z5zy4YxqKp6GPg88Pn+rdMZwDnAe4CpCdS0DHgz8HvA71bVdUl+WlVf\nmUAtv5Dk+l0tAo6ez1pGHFBVDwBU1ZYkLwY+leTJfV2T8O2Rd0D/kGRZVa1P8jRg+4RqOiDJL9Od\n5Cyo/l1tVf0kyY4J1bSjqn4OPJjk+1V1f1/TT5M8PKGaoAvYnwOPpTu7pqp+NN/DKiMO6L/Iegjd\nwegI4O6+vnmtaX8K/keEQ1Vtp/uW8JokB0+ioP5A9N4kn+x/38a+8ZwfDfwacM+0+QGunv9yALgt\nybOq6jqAqnogyVnAJcCvTKim84A/T/L7dDfR+nqSm+huPHjehGo6AriW7rWqJE+qqlv66yKTOkA+\nlOTgqnoQeM7Omf11kEkF/weAdUn+HngB8O6+pim6sJ2EDwI30r07+j3gk0k2A8+ju3PxvNmfxvif\nVlXfm3QdjybJmcDzq+odE67jg8CHquprMyy7tKrOnUBNC+nOHG+dYdnzq+rv5rumke0fDhxPd9De\nWlW3TaqWXelPbo6uqh9MYNuPraqfzTD/KOBJVXXDfNfUb/8ZwNOBb1fVjZOoYbokxwBU1c1JjgRe\nSje8+o15rWN/CX5J0jD7zcc5JUnDGPyS1BiDX5IaY/BLUmMMfklqzP8D1RNCOseGn4gAAAAASUVO\nRK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11d2eae48>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train.Class.value_counts(normalize=True).plot(kind='bar',title='Class distribution in train set')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observation\n",
    "* Class levels 3, 8, and 9 are notably under-represented\n",
    "* Levels 5 and 6 are of comparable, medium-low frequency\n",
    "* Levels 1, 2, and 4 are of comparable, medium-high frequency\n",
    "* Level 7 is clearly the most frequent one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## text cleaning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stemmer=SnowballStemmer(\"english\") # stemmer function from nltk library\n",
    "stop = set(stopwords.words('english')) # also stop words from nltk \n",
    "def clean_the_text(text):\n",
    "    \n",
    "    tokens= nltk.word_tokenize(text) # Tokanize the text \n",
    "    affterstemmer=[]\n",
    "    for word in tokens: # stemm all words with Snowball stemmer one by one\n",
    "        affterstemmer.append(stemmer.stem(word))\n",
    "    \n",
    "    afterstop=[]\n",
    "    for word in affterstemmer: # check all words if they are stop word\n",
    "        if word not in stop:\n",
    "            afterstop.append(word)\n",
    "    return \" \".join(afterstop) # bond all words and return it\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clean_text=[]\n",
    "for i in train_text['Text']:\n",
    "    clean_text.append(clean_the_text(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# CountVectorizer to vectorize the text data\n",
    "# we will be analyzing 100 words\n",
    "count_vect = CountVectorizer(lowercase = True, max_features=100,analyzer='word')\n",
    "\n",
    "tfidf_transformer = TfidfTransformer(use_idf=False)\n",
    "\n",
    "X_train_counts = count_vect.fit_transform(clean_text)\n",
    "\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>Variation</th>\n",
       "      <th>Gene</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.106330</td>\n",
       "      <td>0.044770</td>\n",
       "      <td>0.033578</td>\n",
       "      <td>0.111926</td>\n",
       "      <td>0.016789</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.061559</td>\n",
       "      <td>0.095137</td>\n",
       "      <td>0.072752</td>\n",
       "      <td>0.033578</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005596</td>\n",
       "      <td>0.022385</td>\n",
       "      <td>0.072752</td>\n",
       "      <td>0.011193</td>\n",
       "      <td>0.016789</td>\n",
       "      <td>0.100733</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.016789</td>\n",
       "      <td>Truncating Mutations</td>\n",
       "      <td>FAM58A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.087115</td>\n",
       "      <td>0.046120</td>\n",
       "      <td>0.005124</td>\n",
       "      <td>0.117862</td>\n",
       "      <td>0.061493</td>\n",
       "      <td>0.005124</td>\n",
       "      <td>0.107613</td>\n",
       "      <td>0.066618</td>\n",
       "      <td>0.025622</td>\n",
       "      <td>0.030747</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005124</td>\n",
       "      <td>0.112738</td>\n",
       "      <td>0.030747</td>\n",
       "      <td>0.035871</td>\n",
       "      <td>0.015373</td>\n",
       "      <td>0.148609</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.035871</td>\n",
       "      <td>W802*</td>\n",
       "      <td>CBL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.087115</td>\n",
       "      <td>0.046120</td>\n",
       "      <td>0.005124</td>\n",
       "      <td>0.117862</td>\n",
       "      <td>0.061493</td>\n",
       "      <td>0.005124</td>\n",
       "      <td>0.107613</td>\n",
       "      <td>0.066618</td>\n",
       "      <td>0.025622</td>\n",
       "      <td>0.030747</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005124</td>\n",
       "      <td>0.112738</td>\n",
       "      <td>0.030747</td>\n",
       "      <td>0.035871</td>\n",
       "      <td>0.015373</td>\n",
       "      <td>0.148609</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.035871</td>\n",
       "      <td>Q249E</td>\n",
       "      <td>CBL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.118540</td>\n",
       "      <td>0.062092</td>\n",
       "      <td>0.016934</td>\n",
       "      <td>0.129830</td>\n",
       "      <td>0.022579</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.062092</td>\n",
       "      <td>0.163698</td>\n",
       "      <td>0.050803</td>\n",
       "      <td>0.107251</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005645</td>\n",
       "      <td>0.090316</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.090316</td>\n",
       "      <td>0.073382</td>\n",
       "      <td>0.090316</td>\n",
       "      <td>N454D</td>\n",
       "      <td>CBL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.053684</td>\n",
       "      <td>0.012389</td>\n",
       "      <td>0.012389</td>\n",
       "      <td>0.272548</td>\n",
       "      <td>0.016518</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.033036</td>\n",
       "      <td>0.024777</td>\n",
       "      <td>0.012389</td>\n",
       "      <td>0.004130</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.028907</td>\n",
       "      <td>0.041295</td>\n",
       "      <td>0.074331</td>\n",
       "      <td>0.024777</td>\n",
       "      <td>0.099108</td>\n",
       "      <td>0.008259</td>\n",
       "      <td>0.082590</td>\n",
       "      <td>L399V</td>\n",
       "      <td>CBL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 102 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  0.106330  0.044770  0.033578  0.111926  0.016789  0.000000  0.061559   \n",
       "1  0.087115  0.046120  0.005124  0.117862  0.061493  0.005124  0.107613   \n",
       "2  0.087115  0.046120  0.005124  0.117862  0.061493  0.005124  0.107613   \n",
       "3  0.118540  0.062092  0.016934  0.129830  0.022579  0.000000  0.062092   \n",
       "4  0.053684  0.012389  0.012389  0.272548  0.016518  0.000000  0.033036   \n",
       "\n",
       "          7         8         9   ...          92        93        94  \\\n",
       "0  0.095137  0.072752  0.033578   ...    0.005596  0.022385  0.072752   \n",
       "1  0.066618  0.025622  0.030747   ...    0.005124  0.112738  0.030747   \n",
       "2  0.066618  0.025622  0.030747   ...    0.005124  0.112738  0.030747   \n",
       "3  0.163698  0.050803  0.107251   ...    0.000000  0.000000  0.005645   \n",
       "4  0.024777  0.012389  0.004130   ...    0.000000  0.028907  0.041295   \n",
       "\n",
       "         95        96        97        98        99             Variation  \\\n",
       "0  0.011193  0.016789  0.100733  0.000000  0.016789  Truncating Mutations   \n",
       "1  0.035871  0.015373  0.148609  0.000000  0.035871                 W802*   \n",
       "2  0.035871  0.015373  0.148609  0.000000  0.035871                 Q249E   \n",
       "3  0.090316  0.000000  0.090316  0.073382  0.090316                 N454D   \n",
       "4  0.074331  0.024777  0.099108  0.008259  0.082590                 L399V   \n",
       "\n",
       "     Gene  \n",
       "0  FAM58A  \n",
       "1     CBL  \n",
       "2     CBL  \n",
       "3     CBL  \n",
       "4     CBL  \n",
       "\n",
       "[5 rows x 102 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = pd.DataFrame(data=X_train_tfidf.toarray())# create data frame to bond Gene and Variation together \n",
    "x['Variation'] = train['Variation']\n",
    "x['Gene']= train['Gene']\n",
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>Variation</th>\n",
       "      <th>Gene</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.106330</td>\n",
       "      <td>0.044770</td>\n",
       "      <td>0.033578</td>\n",
       "      <td>0.111926</td>\n",
       "      <td>0.016789</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.061559</td>\n",
       "      <td>0.095137</td>\n",
       "      <td>0.072752</td>\n",
       "      <td>0.033578</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005596</td>\n",
       "      <td>0.022385</td>\n",
       "      <td>0.072752</td>\n",
       "      <td>0.011193</td>\n",
       "      <td>0.016789</td>\n",
       "      <td>0.100733</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.016789</td>\n",
       "      <td>Truncating Mutations</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.087115</td>\n",
       "      <td>0.046120</td>\n",
       "      <td>0.005124</td>\n",
       "      <td>0.117862</td>\n",
       "      <td>0.061493</td>\n",
       "      <td>0.005124</td>\n",
       "      <td>0.107613</td>\n",
       "      <td>0.066618</td>\n",
       "      <td>0.025622</td>\n",
       "      <td>0.030747</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005124</td>\n",
       "      <td>0.112738</td>\n",
       "      <td>0.030747</td>\n",
       "      <td>0.035871</td>\n",
       "      <td>0.015373</td>\n",
       "      <td>0.148609</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.035871</td>\n",
       "      <td>W802*</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.087115</td>\n",
       "      <td>0.046120</td>\n",
       "      <td>0.005124</td>\n",
       "      <td>0.117862</td>\n",
       "      <td>0.061493</td>\n",
       "      <td>0.005124</td>\n",
       "      <td>0.107613</td>\n",
       "      <td>0.066618</td>\n",
       "      <td>0.025622</td>\n",
       "      <td>0.030747</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005124</td>\n",
       "      <td>0.112738</td>\n",
       "      <td>0.030747</td>\n",
       "      <td>0.035871</td>\n",
       "      <td>0.015373</td>\n",
       "      <td>0.148609</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.035871</td>\n",
       "      <td>Q249E</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.118540</td>\n",
       "      <td>0.062092</td>\n",
       "      <td>0.016934</td>\n",
       "      <td>0.129830</td>\n",
       "      <td>0.022579</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.062092</td>\n",
       "      <td>0.163698</td>\n",
       "      <td>0.050803</td>\n",
       "      <td>0.107251</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005645</td>\n",
       "      <td>0.090316</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.090316</td>\n",
       "      <td>0.073382</td>\n",
       "      <td>0.090316</td>\n",
       "      <td>N454D</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.053684</td>\n",
       "      <td>0.012389</td>\n",
       "      <td>0.012389</td>\n",
       "      <td>0.272548</td>\n",
       "      <td>0.016518</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.033036</td>\n",
       "      <td>0.024777</td>\n",
       "      <td>0.012389</td>\n",
       "      <td>0.004130</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.028907</td>\n",
       "      <td>0.041295</td>\n",
       "      <td>0.074331</td>\n",
       "      <td>0.024777</td>\n",
       "      <td>0.099108</td>\n",
       "      <td>0.008259</td>\n",
       "      <td>0.082590</td>\n",
       "      <td>L399V</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 102 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  0.106330  0.044770  0.033578  0.111926  0.016789  0.000000  0.061559   \n",
       "1  0.087115  0.046120  0.005124  0.117862  0.061493  0.005124  0.107613   \n",
       "2  0.087115  0.046120  0.005124  0.117862  0.061493  0.005124  0.107613   \n",
       "3  0.118540  0.062092  0.016934  0.129830  0.022579  0.000000  0.062092   \n",
       "4  0.053684  0.012389  0.012389  0.272548  0.016518  0.000000  0.033036   \n",
       "\n",
       "          7         8         9  ...         92        93        94        95  \\\n",
       "0  0.095137  0.072752  0.033578  ...   0.005596  0.022385  0.072752  0.011193   \n",
       "1  0.066618  0.025622  0.030747  ...   0.005124  0.112738  0.030747  0.035871   \n",
       "2  0.066618  0.025622  0.030747  ...   0.005124  0.112738  0.030747  0.035871   \n",
       "3  0.163698  0.050803  0.107251  ...   0.000000  0.000000  0.005645  0.090316   \n",
       "4  0.024777  0.012389  0.004130  ...   0.000000  0.028907  0.041295  0.074331   \n",
       "\n",
       "         96        97        98        99             Variation  Gene  \n",
       "0  0.016789  0.100733  0.000000  0.016789  Truncating Mutations    85  \n",
       "1  0.015373  0.148609  0.000000  0.035871                 W802*    39  \n",
       "2  0.015373  0.148609  0.000000  0.035871                 Q249E    39  \n",
       "3  0.000000  0.090316  0.073382  0.090316                 N454D    39  \n",
       "4  0.024777  0.099108  0.008259  0.082590                 L399V    39  \n",
       "\n",
       "[5 rows x 102 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder # Encode labels with value between 0 and n_classes-1.\n",
    "encoder  = LabelEncoder()\n",
    "x['Gene'] = encoder.fit_transform(y=x['Gene'])\n",
    "\n",
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>Variation</th>\n",
       "      <th>Gene</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.106330</td>\n",
       "      <td>0.044770</td>\n",
       "      <td>0.033578</td>\n",
       "      <td>0.111926</td>\n",
       "      <td>0.016789</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.061559</td>\n",
       "      <td>0.095137</td>\n",
       "      <td>0.072752</td>\n",
       "      <td>0.033578</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005596</td>\n",
       "      <td>0.022385</td>\n",
       "      <td>0.072752</td>\n",
       "      <td>0.011193</td>\n",
       "      <td>0.016789</td>\n",
       "      <td>0.100733</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.016789</td>\n",
       "      <td>2629</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.087115</td>\n",
       "      <td>0.046120</td>\n",
       "      <td>0.005124</td>\n",
       "      <td>0.117862</td>\n",
       "      <td>0.061493</td>\n",
       "      <td>0.005124</td>\n",
       "      <td>0.107613</td>\n",
       "      <td>0.066618</td>\n",
       "      <td>0.025622</td>\n",
       "      <td>0.030747</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005124</td>\n",
       "      <td>0.112738</td>\n",
       "      <td>0.030747</td>\n",
       "      <td>0.035871</td>\n",
       "      <td>0.015373</td>\n",
       "      <td>0.148609</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.035871</td>\n",
       "      <td>2856</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.087115</td>\n",
       "      <td>0.046120</td>\n",
       "      <td>0.005124</td>\n",
       "      <td>0.117862</td>\n",
       "      <td>0.061493</td>\n",
       "      <td>0.005124</td>\n",
       "      <td>0.107613</td>\n",
       "      <td>0.066618</td>\n",
       "      <td>0.025622</td>\n",
       "      <td>0.030747</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005124</td>\n",
       "      <td>0.112738</td>\n",
       "      <td>0.030747</td>\n",
       "      <td>0.035871</td>\n",
       "      <td>0.015373</td>\n",
       "      <td>0.148609</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.035871</td>\n",
       "      <td>1897</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.118540</td>\n",
       "      <td>0.062092</td>\n",
       "      <td>0.016934</td>\n",
       "      <td>0.129830</td>\n",
       "      <td>0.022579</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.062092</td>\n",
       "      <td>0.163698</td>\n",
       "      <td>0.050803</td>\n",
       "      <td>0.107251</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005645</td>\n",
       "      <td>0.090316</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.090316</td>\n",
       "      <td>0.073382</td>\n",
       "      <td>0.090316</td>\n",
       "      <td>1667</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.053684</td>\n",
       "      <td>0.012389</td>\n",
       "      <td>0.012389</td>\n",
       "      <td>0.272548</td>\n",
       "      <td>0.016518</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.033036</td>\n",
       "      <td>0.024777</td>\n",
       "      <td>0.012389</td>\n",
       "      <td>0.004130</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.028907</td>\n",
       "      <td>0.041295</td>\n",
       "      <td>0.074331</td>\n",
       "      <td>0.024777</td>\n",
       "      <td>0.099108</td>\n",
       "      <td>0.008259</td>\n",
       "      <td>0.082590</td>\n",
       "      <td>1447</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 102 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  0.106330  0.044770  0.033578  0.111926  0.016789  0.000000  0.061559   \n",
       "1  0.087115  0.046120  0.005124  0.117862  0.061493  0.005124  0.107613   \n",
       "2  0.087115  0.046120  0.005124  0.117862  0.061493  0.005124  0.107613   \n",
       "3  0.118540  0.062092  0.016934  0.129830  0.022579  0.000000  0.062092   \n",
       "4  0.053684  0.012389  0.012389  0.272548  0.016518  0.000000  0.033036   \n",
       "\n",
       "          7         8         9  ...         92        93        94        95  \\\n",
       "0  0.095137  0.072752  0.033578  ...   0.005596  0.022385  0.072752  0.011193   \n",
       "1  0.066618  0.025622  0.030747  ...   0.005124  0.112738  0.030747  0.035871   \n",
       "2  0.066618  0.025622  0.030747  ...   0.005124  0.112738  0.030747  0.035871   \n",
       "3  0.163698  0.050803  0.107251  ...   0.000000  0.000000  0.005645  0.090316   \n",
       "4  0.024777  0.012389  0.004130  ...   0.000000  0.028907  0.041295  0.074331   \n",
       "\n",
       "         96        97        98        99  Variation  Gene  \n",
       "0  0.016789  0.100733  0.000000  0.016789       2629    85  \n",
       "1  0.015373  0.148609  0.000000  0.035871       2856    39  \n",
       "2  0.015373  0.148609  0.000000  0.035871       1897    39  \n",
       "3  0.000000  0.090316  0.073382  0.090316       1667    39  \n",
       "4  0.024777  0.099108  0.008259  0.082590       1447    39  \n",
       "\n",
       "[5 rows x 102 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder # Encode labels with value between 0 and n_classes-1.\n",
    "encoder  = LabelEncoder()\n",
    "x['Variation'] = encoder.fit_transform(y=x['Variation'])\n",
    "\n",
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# creating saperate train and test to create not bias enviroment. \n",
    "# train set will be used in training model \n",
    "# test set is for evaluating our model\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, train['Class'], test_size = .25, random_state = 32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the ML model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score # our evaluation function \n",
    "\n",
    "# importing our machine larning models(algorithms)\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## testing the algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.405535499398\n"
     ]
    }
   ],
   "source": [
    "clf1 = GaussianNB()\n",
    "clf1.fit(x_train, y_train)\n",
    "pred1 = clf1.predict(x_test)\n",
    "print(accuracy_score(y_test,pred1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.494584837545\n"
     ]
    }
   ],
   "source": [
    "clf2 = LogisticRegression()\n",
    "clf2.fit(x_train, y_train)\n",
    "pred2 = clf2.predict(x_test)\n",
    "print(accuracy_score(y_test,pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.389891696751\n"
     ]
    }
   ],
   "source": [
    "clf3 = AdaBoostClassifier()\n",
    "clf3.fit(x_train, y_train)\n",
    "pred3 = clf3.predict(x_test)\n",
    "print(accuracy_score(y_test,pred3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.635379061372\n"
     ]
    }
   ],
   "source": [
    "clf4 = GradientBoostingClassifier()\n",
    "clf4.fit(x_train, y_train)\n",
    "pred4 = clf4.predict(x_test)\n",
    "print(accuracy_score(y_test,pred4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.634175691937\n"
     ]
    }
   ],
   "source": [
    "clf6 = xgb.XGBClassifier(max_depth=3, n_estimators=300, learning_rate=0.05)\n",
    "clf6.fit(x_train, y_train)\n",
    "pred6  = clf6.predict(x_test)\n",
    "print(accuracy_score(y_test,pred6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "since clf4 (GradientBoostingClassifier) gives the highest accuracy, I decide to go with that one\n",
    "\n",
    "## tuning the algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "              n_estimators=100, presort='auto', random_state=None,\n",
       "              subsample=1.0, verbose=0, warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'learning_rate': [0.001, 0.01, 0.1], 'n_estimators': [100, 200, 400], 'max_features': ['sqrt', 'log2', None]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV # Exhaustive search over specified parameter values for an estimator.\n",
    "\n",
    "clf = GradientBoostingClassifier() # classifier\n",
    "\n",
    "# defining parameters that we would like to check\n",
    "parameters = {'learning_rate':[0.001,0.01,0.1], \n",
    "              'n_estimators':[  100, 200, 400],\n",
    "             'max_features':['sqrt','log2', None]}\n",
    "\n",
    "grid = GridSearchCV(clf, parameters, cv=5) # grid search function with \n",
    "grid.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.1, 'max_features': 'log2', 'n_estimators': 400}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.636582430806\n"
     ]
    }
   ],
   "source": [
    "clf = grid.best_estimator_\n",
    "clf.fit(x_train, y_train)\n",
    "pred = clf.predict(x_test)\n",
    "print(accuracy_score(y_test,pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Observations\n",
    "\n",
    "I was expecting higher accuracy score but unfortunately it seems hard with this process, at this point I would like to do one of this two things. \n",
    "\n",
    "1. Differnt Approach: if I can create differnt processing and create new features it might get a better outcome. but this process would take more time than other and outcome is not guaranted.\n",
    "2. Change system out come: in first approach, what i want to do is, create algorithm that can return the class. but since we are getting low accuracy I want to change the output to be probability of being any all classes.\n",
    "\n",
    "Since first one is not promising any better output, I decited to go with second option. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1.87318383e-03,   1.29825825e-04,   1.57163799e-05,\n",
       "         5.67927874e-04,   1.48845720e-03,   9.95820691e-01,\n",
       "         1.04047899e-04,   2.19333642e-08,   1.28430475e-07])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# return the predict Probability \n",
    "\n",
    "\n",
    "pred_prob = clf.predict_proba(x_test)\n",
    "\n",
    "pred_prob[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
